<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Evaluation | Reese Hansen</title>
    <link rel="stylesheet" href="css/styles.css">
</head>
<body>
    <header>
        <nav>
            <a href="index.html">Home</a>
            <a href="lab02.html" class="active">Lab 2: AI Evaluation</a>
            <!-- Add more lab links as the semester progresses -->
        </nav>
        <h1>AI Tool Evaluation</h1>
    </header>

    <main>
        <section>
            <h2>Introduction</h2>
            <p>Brief intro to what you explored and why...</p>
        </section>

        <section>
            <h2>Tool 1: Adobe Firefly</h2>
            <h3>Capabilities</h3>
            <p>Adobe Firefly is an AI image generation tool. it works off of the language within your prompt to create an image. It has to ability to customize your image parameters from widescreen, landscape, square, portrait to vertical. This tool is able to alter images well with only slight changes to its given prompt. It only offers five free images without a subscription; So, if you're trying to achieve exactly what you want asthetically from your image, five tries will likely not be enough. This tool generates clear images well and alters them correctl based on the prompting. It's limited in its ability to take all aspects of the prompt correctly. The longer and more specific the prompt, the better the output. Multiple changes in the output occur with each new image even if the user only changes one aspect of the prompt.  </p>

            <h3>Appropriate Use</h3>
            <p>Adobe Firefly is best for general image generation; however, it's not best for creating specific images since the AI takes creative libertity when creating an image. This tool is well suited for general creative brainstorming. I see Adobe Firefly being useful in campaign or social media post ideas. For example, if you are planning a campign for a company and want to explain your vision better, using AI generated images would be useful to bridge the gap between vision and execution. This tool would be innapripriate to use for a real campign or post because it is poorly executed and clearly AI generated. People may interpret the purpose or content as fake if it's accompanied by clearly AI generated content. This does not replace human judgement because it is based on the prompt put in. Humans are looking for different styles, aesthetics, and messaging behind an image. AI cannot properly asses the "best" image that would ressonate with consumers the most just based on the data given within this platform. Humans are necessary to guide and find problems within the image from a design and customer-focused approach. This does reduce time spent creating or articulating a visual goal. It provides efficiency within the larger workflow. </p>

            <h3>Ethical Considerations</h3>
            <p>Adobe Firefly was trained using existing Adobe platform data. Adobe Stock offers high quality stock images with a large variety of content. From this, Adobe Firefly use existing images as apart of its new AI creations. Adobe Firefly also uses liscened content and public-domain materials in image generation. Adobe's goal with Firefly is to use existing data that has the right to be used commercially, instead of basing content primarily off of unlicensed web content. There are biases within Adobe Firefly. The platform overepresents western aesthetics and design. This is most likely due to the limited stock images used. It lacks a wide range of racial, gender, and cultural diversity when unprompted to do so. Since Adobe Firefily is designed to be commercially safe the risk of copyright infrigement is less compared to other models that use scraped data. The challenges of using AI generated images poses questions about of proper attribution. The correct authorship of artwork goes to Adobe when using this platform. The key to using this platform is transparency about the AI use. Gaps still remain as users may not understand if using content is safe. Bias within the platform is based on the stock images and unclear where it lacks. As AI tools continue to evolve it is the user's responsibility to cite the image source correctly. To properly cite Adobe Firefly you must include "image generated using the prompt "[prompt]" by Adobe, Adobe Firefly,[year](URL)"     </p>

            <!-- Add screenshots or examples -->
            <figure class="viz-container">
                <img src="images/firefly01image.png" alt="firefly 01 image "> 
                <figcaption> Citation: Image generated using the prompt "generate a promotional social media post for a clothing brand that sells jeans. use red, blue, denim, and other colors relevant to the brand. include clothing products and make it look aesthetically vintage," by Adobe, Adobe Firefly, 2026 (https://firefly.adobe.com/)   </figcaption>
            </figure>

            My goal using Adobe Firefly was to create an advertising campaign for a fake clothing brand. I wanted the brand to be similar to Levi's, using colors like red and blue. I also wanted the AI generated campign to focus on familial values and traditional farm life. This first generated image lacked consumer appeal and storytelling within the campiagn. Adobe Firefly produced the image to the above, which lacked interest. However, it did adequately show denim clothing to promote the fake brand. Each citation to the right of each image includes the prompt written into Adobe Firefly. 



           <figure class="viz-container">
                <img src="images/firefly02image.png" alt="firefly 02 image ">
                <figcaption> Citation: Image generated using the prompt "generate a promotional social media post for a clothing brand that sells jeans. use red, blue, denim, and other colors relevant to the brand. include clothing products and make it look aesthetically vintage. include a barn and open green field. add people wearing denim outfits with cowboy hats and cowboy boots. make it have a farm like feel. feel free to add any animals and make it a wide shot photo," by Adobe, Adobe Firefly, 2026 (https://firefly.adobe.com/)</figcaption>
            </figure>

            With this new prompt, I wanted the AI to add people and include a country farm enviornment. I wanted more vibrnt colors, so i prompted it to add green grass. I also included what the poeples' outfits should include: cowboy boots, cowboy hats, and denim outfits to promote the brand. This was an improvement from the first image as it represented the fake brand's country life appeal. The people within the image looked too AI generated and the backround was blurred. I wanted more diversity within my image and more visual interest. Four men standing together felt inauthentic and awkward. 


            <figure class="viz-container">
                <img src="images/firefly04image.png" alt="firefly 04 image ">
                <figcaption>Citation: Image generated using the prompt "generate a promotional social media post for a clothing brand that sells jeans. use red, blue, denim, and other colors relevant to the brand. include clothing products and make it look aesthetically vintage. include a barn and open green field. add people wearing denim outfits with cowboy hats and cowboy boots. make it have a farm like feel. feel free to add any animals and make it a wide shot photo. include one man, one woman, and one child. have them sitting on the porch of the white barn. the man is holding a beer. the lighting in golden hour with an incoming warm sunset," by Adobe, Adobe Firefly, 2026 (https://firefly.adobe.com/)</figcaption>
            </figure>

            To improve the privious image, I added more specific langauge about the setting. I added that the image should represent a wide shot photo to allow more of the field to be in focus. I also added specifics about age and gender to create more diversity within the fake campiagn image. I prompted Adobe Firefly to have the described family sittig on a pourch of a white barn. I also included lighting changes to be golden hour. I found that short scentences that do not conflict with each other create better images. Originally in this prompt, I had included a phrase about adding a "warm sunset." The AI did not understand the complexity and worked best with the phrase "golden hour" instead. I was quite happy with the drastic change between image two and three. This image for a denim brand campiagn better tells a story about family, love, and hard working Americans by using a farm landscape. 



            <figure class="viz-container">
                <img src="images/firefly03image.png" alt="firefly 03 image ">
                <figcaption>Citation: Image generated using the prompt "generate a promotional social media post for a clothing brand that sells jeans. use red, blue, denim, and other colors relevant to the brand. include clothing products and make it look aesthetically vintage. include a barn and open green field. add people wearing denim outfits with cowboy hats and cowboy boots. make it have a farm like feel. feel free to add any animals and make it a wide shot photo. include one man, one woman, and one child. have them sitting on the porch of the white barn. the lighting in golden hour. use a wider camera angle with more field showing. add the slogan "Tradition in Every Stitch" somewhere on the page so it looks like an advertisement," by Adobe, Adobe Firefly, 2026 (https://firefly.adobe.com/)</figcaption>
            </figure>  

            When generating image four, I decided that this denim campaign needed a slogan. Based on the brand's familial values I wanted the focus to be on tradition; so, I came up with the slogan "Tradition in Every Stitch." I prompted that the slogan could be anywhere on the image and should look like a real advertisment. I did not specify font. I did not prefer the font chosen but do believe AI chose an outdorsey and rough font that matched the content prompted. I was not intending for the actual image to change as drastically as it did. Even though I still prompted one man, one woman, and one child in the photo, the AI did not follow that correctly. Instead, it generated an image with two men and one child. It also changed the cows in the background and the race of the three people. I think if I had specified to keep the content of the previous image the same it would have just added the slogna and not altered the image. Within Adobe Firefly you can tag reference images on the side to keep them and further alter them. Given this was my first time using Firefly, I wasn't aware of that tool. This generated image is my favorite. I believe the lighting, font, and people pictured correctly represent to brand's target audience: family orientated, hard working, and country.  


            <figure class="viz-container">
                <img src="images/firefly05image.png" alt="firefly 05 image ">
                <figcaption> Citation: Image generated using the prompt "generate a promotional social media post for a clothing brand that sells jeans. use red, blue, denim, and other colors relevant to the brand. include clothing products and make it look aesthetically vintage. include a barn and open green field. add people wearing denim outfits with cowboy hats and cowboy boots. make it have a farm like feel. feel free to add any animals and make it a wide shot photo. include one man, one woman, and one child. have them sitting on the porch of the white barn. the lighting in golden hour. add more field showing. add the slogan "Tradition in Every Stitch" somewhere on the page so it looks like an advertisement.  make the people in the image smiling. make one of the man's race be white. change the font of the previous "Tradition in Every Stitch," by Adobe, Adobe Firefly, 2026 (https://firefly.adobe.com/) </figcaption>
            </figure>  

            Although image four was my favorite image, I still tried to alter it further. I wanted the people to be smiling and to change the font. I also prompted for one man to change races in order to showcase more diversity within the campiagn. Instead, the AI generated two white women and one white man. It made more drastic changes to the privious image than I had anticipated, even though the prompts were very similar. I did not prefer the larger size or chosen font for this image in comparison to image four. In the future, inputting a specific font and size demensions would help the AI better capture the users' vision.   
            
        

        </section>

        <section>
            <h2>Tool 2: Runway</h2>
            <!-- Same structure as Tool 1 -->


            <h3>Capabilities</h3>
            <p>Runway has the ability to AI generate short videos from images, prompts, and existing footage. Runway is able to alter backgrounds, change stayles, and uses motion tracking to move people or things in the video. It creates a video within seconds based on the input given. It allows for creativity and exploration into video production. It does struggle with following the exact prompt given. People in its AI generated videos often have disorted limbs or move unnaturally. It does not compare to classic video editors. The platform struggles with complicated prompts and results are often not coherant. The intended storytelling is often lost. The best way to achieve what you want from Runway is specififc clear short scentences. It's best to describe the camera angle, mood, and placing of any additional figures. </p>



            <h3>Appropriate Use</h3>
            <p>Runway is best used publically for short form content, like short social media posts. It is also helpful in the creative process. It allows the user to test and visualize a video concept. This platform would not be best used in professional public work like journals or a documentry. The AI is not perfect and cannot produce correct footage without human overview. If sensitive subjects that require context or realism are involved, this platofrom would not be ideal. Runway would help make workflow more efficient as it allows storyboards and concepts to come to life. It would be helpful in early stages of planning of a visual model or campign. It is very important that work generated by Runway has human oversight because of its unpredictable nature. </p>




            <h3>Ethical Considerations</h3>
            <p>Runway was trained on a conbination of licensed data, human-created content, and publically avalible material. The exact datasets are not disclosed. Similarly to Adobe Firefly, Runway has biases. It overrepresents western society and may display sterotypes based on the prompt interpretation. The proper authorship of content is confusing when it comes to Runway. It allows users to generate videos from their own images, but because the creation is done by AI, attribution must also be properly cited to Runway. When using pre-generated content from Runway, the true ownership is unclear. There are still major gaps within the technology. There are limited watermarks in palce to properly safeguard content. There are also limited usage and filter policies, as content may mimic copyrighted styles of content. The best way to cite Runway is clearly state the video is AI-generated. Within my citation below, I cite myself and Runway. It is also best to fact check all work produced by AI with real world examples and evidence.   </p>



            <h2>Photos and Animations</h2>

            <!-- Add screenshots or examples -->
             <figure class="viz-container">
                <img src= "images/ocean.png" alt="beach photo">
                <figcaption>Photo citation: Hansen, Reese. Eileen at Seagrove Beach, FL. 2023. Author's personal collection.
                </figcaption>

                <figcaption>Runway video ciation: Hansen, Reese. (2026). Beachside Smile Animation (AI-generated video). Runway Gen-4 Turbo. https://app.runwayml.com/video-tools/teams/reesehansen4/ai-tools/generate?sessionId=984210e1-68de-4396-8e22-d5d148658661&tool=video&mode=tools 
                </figcaption>
            </figure>


            <video controls width="600">
              <source src="Beach_Animation.mp4" type="video/mp4">
        
        <!-- Fallback text for browsers that don't support the video tag -->
        Your browser does not support the video tag.
             </video>


             My prompt to Runway was simple and short: "Make the ocean waves me moving behind the person in the video. add natural wind. make the person look the other way then back keeping smiling." I already liked the filter and style of the photo because it was taken on film. I decided not to alter that or the framing to understand the platforms basic capabilities first. The AI did not correctly follow my prompt. Instead of the woman turning around, it made the woman look like her was talking. I was pleased with the natural looking wind and ocean waves in the background. I have not tested AI video production before and found its creation to be interesting and fun. 


             <figure class="viz-container">
                <img src= "images/florida.png" alt="florida photo">
                <figcaption>Photo citation: Hansen, Reese. Febuary in Seagrove Beach, FL. 2024. Author's personal collection.
                </figcaption>

                <figcaption>Runway video ciation: Hansen, Reese. (2026). Beachside ATV Animation (AI-generated video). Runway Gen-4 Turbo. https://app.runwayml.com/video-tools/teams/reesehansen4/ai-tools/generate?sessionId=984210e1-68de-4396-8e22-d5d148658661&tool=video&mode=tools 
                </figcaption>
            </figure>


            <video controls width="400">
              <source src="atv_01.mp4" type="video/mp4">

        <!-- Fallback text for browsers that don't support the video tag -->
        Your browser does not support the video tag.
             </video>



            <video controls width="400">
              <source src="atv_01.mp4" type="video/mp4">

        <!-- Fallback text for browsers that don't support the video tag -->
        Your browser does not support the video tag.
             </video>









        </section>







        
        <section>
            <h2>Broader Reflections</h2>
            <p>Personal use, DCDA context, evolving landscape...</p>
        </section>
    </main>

    <footer>
        <p>&copy; 2026 Your Name | <a href="https://github.com/yourusername/dcda-portfolio">GitHub</a></p>
    </footer>
</body>
</html>