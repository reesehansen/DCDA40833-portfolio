<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Evaluation | Reese Hansen</title>
    <link rel="stylesheet" href="css/styles.css">
</head>
<body>
    <header>
        <nav>
            <a href="index.html">Home</a>
            <a href="lab02.html" class="active">Lab 2: AI Evaluation</a>
            <!-- Add more lab links as the semester progresses -->
        </nav>
        <h1>AI Tool Evaluation</h1>
    </header>

    <main>
        <section>
            <h2>Introduction</h2>
            <p>In Lab 2, I wanted to explore design and new creative AI tools. I decided to test Adobe Firefly, an image generator, and Runway, a video production tool. I have not explored many new AI image and video tools, and wanted to see what each was capable of. I enjoy design, marketing, and campaign creation. I thought these tools would be useful to me academically and professionally in situations where I want to bring a creative vision to life.  </p>
        </section>

        <section>
            <h2>Tool 1: Adobe Firefly</h2>
            <h3>Capabilities</h3>
            <p>Adobe Firefly is an AI image generation tool. it works off of the language within your prompt to create an image. It has to ability to customize your image parameters from widescreen, landscape, square, portrait to vertical. This tool is able to alter images well with only slight changes to its given prompt. It only offers five free images without a subscription; So, if you're trying to achieve exactly what you want asthetically from your image, five tries will likely not be enough. This tool generates clear images well and alters them correctl based on the prompting. It's limited in its ability to take all aspects of the prompt correctly. The longer and more specific the prompt, the better the output. Multiple changes in the output occur with each new image even if the user only changes one aspect of the prompt.  </p>

            <h3>Appropriate Use</h3>
            <p>Adobe Firefly is best for general image generation; however, it's not best for creating specific images since the AI takes creative libertity when creating an image. This tool is well suited for general creative brainstorming. I see Adobe Firefly being useful in campaign or social media post ideas. For example, if you are planning a campign for a company and want to explain your vision better, using AI generated images would be useful to bridge the gap between vision and execution. This tool would be innapripriate to use for a real campign or post because it is poorly executed and clearly AI generated. People may interpret the purpose or content as fake if it's accompanied by clearly AI generated content. This does not replace human judgement because it is based on the prompt put in. Humans are looking for different styles, aesthetics, and messaging behind an image. AI cannot properly asses the "best" image that would ressonate with consumers the most just based on the data given within this platform. Humans are necessary to guide and find problems within the image from a design and customer-focused approach. This does reduce time spent creating or articulating a visual goal. It provides efficiency within the larger workflow. </p>

            <h3>Ethical Considerations</h3>
            <p>Adobe Firefly was trained using existing Adobe platform data. Adobe Stock offers high quality stock images with a large variety of content. From this, Adobe Firefly use existing images as apart of its new AI creations. Adobe Firefly also uses liscened content and public-domain materials in image generation. Adobe's goal with Firefly is to use existing data that has the right to be used commercially, instead of basing content primarily off of unlicensed web content. There are biases within Adobe Firefly. The platform overepresents western aesthetics and design. This is most likely due to the limited stock images used. It lacks a wide range of racial, gender, and cultural diversity when unprompted to do so. Since Adobe Firefily is designed to be commercially safe the risk of copyright infrigement is less compared to other models that use scraped data. The challenges of using AI generated images poses questions about of proper attribution. The correct authorship of artwork goes to Adobe when using this platform. The key to using this platform is transparency about the AI use. Gaps still remain as users may not understand if using content is safe. Bias within the platform is based on the stock images and unclear where it lacks. As AI tools continue to evolve it is the user's responsibility to cite the image source correctly. To properly cite Adobe Firefly you must include "image generated using the prompt "[prompt]" by Adobe, Adobe Firefly,[year](URL)"     </p>

            <!-- Add screenshots or examples -->
            <figure class="viz-container">
                <img src="images/firefly01image.png" alt="firefly 01 image "> 
                <figcaption> Citation: Image generated using the prompt "generate a promotional social media post for a clothing brand that sells jeans. use red, blue, denim, and other colors relevant to the brand. include clothing products and make it look aesthetically vintage," by Adobe, Adobe Firefly, 2026 (https://firefly.adobe.com/)   </figcaption>
            </figure>

            My goal using Adobe Firefly was to create an advertising campaign for a fake clothing brand. I wanted the brand to be similar to Levi's, using colors like red and blue. I also wanted the AI generated campign to focus on familial values and traditional farm life. This first generated image lacked consumer appeal and storytelling within the campiagn. Adobe Firefly produced the image to the above, which lacked interest. However, it did adequately show denim clothing to promote the fake brand. Each citation to the right of each image includes the prompt written into Adobe Firefly. 



           <figure class="viz-container">
                <img src="images/firefly02image.png" alt="firefly 02 image ">
                <figcaption> Citation: Image generated using the prompt "generate a promotional social media post for a clothing brand that sells jeans. use red, blue, denim, and other colors relevant to the brand. include clothing products and make it look aesthetically vintage. include a barn and open green field. add people wearing denim outfits with cowboy hats and cowboy boots. make it have a farm like feel. feel free to add any animals and make it a wide shot photo," by Adobe, Adobe Firefly, 2026 (https://firefly.adobe.com/)</figcaption>
            </figure>

            With this new prompt, I wanted the AI to add people and include a country farm enviornment. I wanted more vibrnt colors, so i prompted it to add green grass. I also included what the poeples' outfits should include: cowboy boots, cowboy hats, and denim outfits to promote the brand. This was an improvement from the first image as it represented the fake brand's country life appeal. The people within the image looked too AI generated and the backround was blurred. I wanted more diversity within my image and more visual interest. Four men standing together felt inauthentic and awkward. 


            <figure class="viz-container">
                <img src="images/firefly04image.png" alt="firefly 04 image ">
                <figcaption>Citation: Image generated using the prompt "generate a promotional social media post for a clothing brand that sells jeans. use red, blue, denim, and other colors relevant to the brand. include clothing products and make it look aesthetically vintage. include a barn and open green field. add people wearing denim outfits with cowboy hats and cowboy boots. make it have a farm like feel. feel free to add any animals and make it a wide shot photo. include one man, one woman, and one child. have them sitting on the porch of the white barn. the man is holding a beer. the lighting in golden hour with an incoming warm sunset," by Adobe, Adobe Firefly, 2026 (https://firefly.adobe.com/)</figcaption>
            </figure>

            To improve the privious image, I added more specific langauge about the setting. I added that the image should represent a wide shot photo to allow more of the field to be in focus. I also added specifics about age and gender to create more diversity within the fake campiagn image. I prompted Adobe Firefly to have the described family sittig on a pourch of a white barn. I also included lighting changes to be golden hour. I found that short scentences that do not conflict with each other create better images. Originally in this prompt, I had included a phrase about adding a "warm sunset." The AI did not understand the complexity and worked best with the phrase "golden hour" instead. I was quite happy with the drastic change between image two and three. This image for a denim brand campiagn better tells a story about family, love, and hard working Americans by using a farm landscape. 



            <figure class="viz-container">
                <img src="images/firefly03image.png" alt="firefly 03 image ">
                <figcaption>Citation: Image generated using the prompt "generate a promotional social media post for a clothing brand that sells jeans. use red, blue, denim, and other colors relevant to the brand. include clothing products and make it look aesthetically vintage. include a barn and open green field. add people wearing denim outfits with cowboy hats and cowboy boots. make it have a farm like feel. feel free to add any animals and make it a wide shot photo. include one man, one woman, and one child. have them sitting on the porch of the white barn. the lighting in golden hour. use a wider camera angle with more field showing. add the slogan "Tradition in Every Stitch" somewhere on the page so it looks like an advertisement," by Adobe, Adobe Firefly, 2026 (https://firefly.adobe.com/)</figcaption>
            </figure>  

            When generating image four, I decided that this denim campaign needed a slogan. Based on the brand's familial values I wanted the focus to be on tradition; so, I came up with the slogan "Tradition in Every Stitch." I prompted that the slogan could be anywhere on the image and should look like a real advertisment. I did not specify font. I did not prefer the font chosen but do believe AI chose an outdorsey and rough font that matched the content prompted. I was not intending for the actual image to change as drastically as it did. Even though I still prompted one man, one woman, and one child in the photo, the AI did not follow that correctly. Instead, it generated an image with two men and one child. It also changed the cows in the background and the race of the three people. I think if I had specified to keep the content of the previous image the same it would have just added the slogna and not altered the image. Within Adobe Firefly you can tag reference images on the side to keep them and further alter them. Given this was my first time using Firefly, I wasn't aware of that tool. This generated image is my favorite. I believe the lighting, font, and people pictured correctly represent to brand's target audience: family orientated, hard working, and country.  


            <figure class="viz-container">
                <img src="images/firefly05image.png" alt="firefly 05 image ">
                <figcaption> Citation: Image generated using the prompt "generate a promotional social media post for a clothing brand that sells jeans. use red, blue, denim, and other colors relevant to the brand. include clothing products and make it look aesthetically vintage. include a barn and open green field. add people wearing denim outfits with cowboy hats and cowboy boots. make it have a farm like feel. feel free to add any animals and make it a wide shot photo. include one man, one woman, and one child. have them sitting on the porch of the white barn. the lighting in golden hour. add more field showing. add the slogan "Tradition in Every Stitch" somewhere on the page so it looks like an advertisement.  make the people in the image smiling. make one of the man's race be white. change the font of the previous "Tradition in Every Stitch," by Adobe, Adobe Firefly, 2026 (https://firefly.adobe.com/) </figcaption>
            </figure>  

            Although image four was my favorite image, I still tried to alter it further. I wanted the people to be smiling and to change the font. I also prompted for one man to change races in order to showcase more diversity within the campiagn. Instead, the AI generated two white women and one white man. It made more drastic changes to the privious image than I had anticipated, even though the prompts were very similar. I did not prefer the larger size or chosen font for this image in comparison to image four. In the future, inputting a specific font and size demensions would help the AI better capture the users' vision.   
            
        

        </section>

        <section>
            <h2>Tool 2: Runway</h2>
            <!-- Same structure as Tool 1 -->


            <h3>Capabilities</h3>
            <p>Runway has the ability to AI generate short videos from images, prompts, and existing footage. Runway is able to alter backgrounds, change stayles, and uses motion tracking to move people or things in the video. It creates a video within seconds based on the input given. It allows for creativity and exploration into video production. It does struggle with following the exact prompt given. People in its AI generated videos often have disorted limbs or move unnaturally. It does not compare to classic video editors. The platform struggles with complicated prompts and results are often not coherant. The intended storytelling is often lost. The best way to achieve what you want from Runway is specififc clear short scentences. It's best to describe the camera angle, mood, and placing of any additional figures. </p>



            <h3>Appropriate Use</h3>
            <p>Runway is best used publically for short form content, like short social media posts. It is also helpful in the creative process. It allows the user to test and visualize a video concept. This platform would not be best used in professional public work like journals or a documentry. The AI is not perfect and cannot produce correct footage without human overview. If sensitive subjects that require context or realism are involved, this platofrom would not be ideal. Runway would help make workflow more efficient as it allows storyboards and concepts to come to life. It would be helpful in early stages of planning of a visual model or campign. It is very important that work generated by Runway has human oversight because of its unpredictable nature. </p>




            <h3>Ethical Considerations</h3>
            <p>Runway was trained on a conbination of licensed data, human-created content, and publically avalible material. The exact datasets are not disclosed. Similarly to Adobe Firefly, Runway has biases. It overrepresents western society and may display sterotypes based on the prompt interpretation. The proper authorship of content is confusing when it comes to Runway. It allows users to generate videos from their own images, but because the creation is done by AI, attribution must also be properly cited to Runway. When using pre-generated content from Runway, the true ownership is unclear. There are still major gaps within the technology. There are limited watermarks in palce to properly safeguard content. There are also limited usage and filter policies, as content may mimic copyrighted styles of content. The best way to cite Runway is clearly state the video is AI-generated. Within my citation below, I cite myself and Runway. It is also best to fact check all work produced by AI with real world examples and evidence.   </p>



            <h2>Beach Film Photo and Animation</h2>

            <!-- Add screenshots or examples -->
             <figure class="viz-container">
                <img src= "images/ocean.png" alt="beach photo">
                <figcaption>Photo citation: Hansen, Reese. Eileen at Seagrove Beach, FL. 2023. Author's personal collection.
                </figcaption>

                <figcaption>Runway video ciation: Hansen, Reese. (2026). Beachside Smile Animation (AI-generated video). Runway Gen-4 Turbo. https://app.runwayml.com/video-tools/teams/reesehansen4/ai-tools/generate?sessionId=984210e1-68de-4396-8e22-d5d148658661&tool=video&mode=tools 
                </figcaption>
            </figure>


            <video controls width="600">
              <source src="Beach_Animation.mp4" type="video/mp4">
        
        <!-- Fallback text for browsers that don't support the video tag -->
        Your browser does not support the video tag.
             </video>


             <p> My prompt to Runway was simple and short: "Make the ocean waves me moving behind the person in the video. add natural wind. make the person look the other way then back keeping smiling." I already liked the filter and style of the photo because it was taken on film. I decided not to alter that or the framing to understand the platforms basic capabilities first. The AI did not correctly follow my prompt. Instead of the woman turning around, it made the woman look like her was talking. I was pleased with the natural looking wind and ocean waves in the background. I have not tested AI video production before and found its creation to be interesting and fun.
             </p>







            <h2>Beach ATV Photo and Animations</h2>




             <figure class="viz-container">
                <img src= "images/florida.png" alt="florida photo">
                <figcaption>Photo citation: Hansen, Reese. Febuary in Seagrove Beach, FL. 2024. Author's personal collection.
                </figcaption>

                <figcaption>Runway video ciation: Hansen, Reese. (2026). Beachside ATV Animation (AI-generated video). Runway Gen-4 Turbo. https://app.runwayml.com/video-tools/teams/reesehansen4/ai-tools/generate?sessionId=984210e1-68de-4396-8e22-d5d148658661&tool=video&mode=tools 
                </figcaption>
            </figure>


            <video controls width="400">
              <source src="atv_01.mp4" type="video/mp4">

        <!-- Fallback text for browsers that don't support the video tag -->
        Your browser does not support the video tag.
             </video>


            <figure class="viz-container">
             <figcaption> Prompt: "make a red and black atv car drive through the right to the left. make the lighting warmer. add small birding flying in the horizon." 

             </figcaption>
            </figure>




            <video controls width="400">
              <source src="atv_02.mp4" type="video/mp4">

        <!-- Fallback text for browsers that don't support the video tag -->
        Your browser does not support the video tag.
             </video>

            <figure class="viz-container">    
             <figcaption> Prompt: "make a red and black atv car drive from the left to the right. make the lighting warmer. add a pink toned sunset in the clouds. add small birding flying in the horizon."

            </figcaption>
            </figure>



            <video controls width="400">
              <source src="atv_03.mp4" type="video/mp4">

        <!-- Fallback text for browsers that don't support the video tag -->
        Your browser does not support the video tag.
             </video>

            <figure class="viz-container">  
           <figcaption> Prompt: "make a red and black atv car drive from the left to the right. make the lighting warmer. make the clouds pink and orange. add a flock of small birds flying in the same direction as the atvs." 

           </figcaption>
            </figure>




             <p> Within these three videos I attempted to prompt Runway to add a larger object. In this case, I promopted an ATV to drive through the beach. I wanted birds flying in the horizon as well. I also attempted to change the lighting by prompting a pink and orange sunset and clouds in different prompts. Not all of the animations kept each element that I wanted them to. When I complicated the prompt just slightly, at least one piece was not implemented. The second video is most like what I wanted the final product to look like. I struggled to prompt Runway in the way I wanted. The three videos ended up looking quite similar, even though that was not my intention because some of the output was not changed. 
             </p>



        </section>







        
        <section>
            <h2>Broader Reflections</h2>
            <p>As stated above in each of the Capabilities, Appropriate Use, and Ethical Considerations sections pertaining to each tool, there are pros and cons when it comes to AI-generated imaging and video production. These tools are best used in the early development stages of a project. AI image and video generation allow users to test ideas and bring storyboards to life. In the design and marketing world, using AI to help express a vision for a project would be useful. However, some concerns automatically come with any AI use. The main problem is authorship. Depending on what data a platform is using to help run its content, the authorship is often vague or unknown. If using AI, it is best to cite the platform and author of a preselected image if possible. As developers continue to expand and fine-tune programs, this concern must be addressed. Clear and correct authorship should be easier to find when using AI platforms. 

            I think AI is best used in the early development of a project, academically or professionally. In addition, I find AI tools helpful in explaining a topic or breaking down large blocks of text. Creatively, the tools I tested above, Adobe Firefly and Runway, will be helpful in design and campaign idea generation. Other tools I did not test, like ChatGPT and Gemini, are great ways to understand complicated content and present it in new ways, like charts or podcasts. It is very important that you do not gain whole ideas or take ownership of content directly from AI-generated platforms. I find them best used in planning and comprehensive analysis scenarios, but not in project execution. In relation to the DCDA program, these tools can be positive in troubleshooting code and aiding in design, but do not replace the human eye. Humans are still very necessary and should always fact-check AI content. AI usually cannot comprehend a complicated plan and fully understand someone's vision. This is where humans are crucial. I think that humans working with code are more vulnerable to AI replacing human roles than art-focused professions, but humans are still needed in both areas. 

            When analyzing a new AI tool in the future, it is important to research where the platform generates its content from. Certain biases and issues come with new AI tools as developers navigate foreign programming. Citations are important when using work that is generated by AI because, in many cases, true authorship is unknown. To best avoid citing incorrect ownership, follow citation guidelines on the platform's website and always state content that is AI-generated. Personally, when evaluating new tools, I look to see how I can benefit from a platform. I also analyze what settings an AI model would be appropriate to use in. Tools are rapidly developing and offering solutions to challenges, and making workflow more efficient. AI can reduce the time spent on a project and make your life easier in many ways. Convenience is important to consumers, and I predict AI will continue to advance and expand as far as it can legally. However, I believe the importance of the human eye, emotional complexity, and discretion will always be necessary when using AI tools. 
</p>
        </section>
    </main>

    <footer>
        <p>&copy; 2026 Reese Hansen | <a href="https://github.com/reesehansen/dcda-portfolio">GitHub</a></p>
    </footer>
</body>
</html>